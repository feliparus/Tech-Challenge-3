{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69dd28f0-0404-44f6-9037-5a7fde23cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from include.utils import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW, DistilBertForSequenceClassification, DistilBertTokenizerFast, EarlyStoppingCallback, Trainer, TrainingArguments\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4da6d01-83e0-4ae2-a65b-ca2f3d106d20",
   "metadata": {},
   "source": [
    "**Objetivo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99681563-d1d2-40d2-bb74-e0ac77c736ea",
   "metadata": {},
   "source": [
    "Preparar e ajustar um modelo DistilBERT pré-treinado para realizar a classificação de textos com base em um conjunto de dados específico.\n",
    "\n",
    "Utilizaremos o DistilBERT, uma versão otimizada e mais leve do BERT, para realizar a tarefa de classificação de textos. O fine-tuning será realizado para aprimorar a precisão e a consistência do modelo com base no estilo e nas características dos documentos fornecidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dadbba7-fa2c-47e0-9f97-f675d56234c8",
   "metadata": {},
   "source": [
    "**Preparação dos dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13a542e-d15b-4965-8a70-da93f3dddd00",
   "metadata": {},
   "source": [
    "Carregamos os dados de um arquivo Parquet e verificamos se a coluna de rótulos está presente. Caso não esteja, geramos rótulos sintéticos para possibilitar o treinamento do modelo. Em seguida, aplicamos uma amostragem opcional para limitar o tamanho do dataset, facilitando o teste inicial e a validação do fluxo de trabalho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "762a4e8b-be48-4588-a94b-e00826d88eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuando o processamento a partir do índice 70600.\n",
      "Usando uma amostra de 5000 registros.\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "diretorio_arquivos = '../arquivos'\n",
    "parquet_file_path = os.path.join(diretorio_arquivos, 'trn.parquet')\n",
    "diretorio_finetunning_results = os.path.join(diretorio_arquivos, 'finetunning', 'results')\n",
    "diretorio_finetunning_logs = os.path.join(diretorio_arquivos, 'finetunning', 'logs')\n",
    "diretorio_finetunning_modelo_final = os.path.join(diretorio_arquivos, 'finetunning', 'modelo_final')\n",
    "processed_indices_file_path = os.path.join(diretorio_arquivos, 'finetunning', 'processed_indices.npy')\n",
    "\n",
    "# Carregar DataFrame do Parquet\n",
    "dados = load_dataframe(parquet_file_path)\n",
    "\n",
    "# Gerando rótulo sintético\n",
    "if 'label' not in dados.columns:\n",
    "    np.random.seed(42)  # Para reprodutibilidade\n",
    "    dados['label'] = np.random.randint(0, 2, size=len(dados))\n",
    "\n",
    "# Configurações de amostragem e processamento\n",
    "batch_size = 5000\n",
    "use_sample = True\n",
    "\n",
    "# Determinar o índice inicial para processamento\n",
    "start_idx = 0\n",
    "if os.path.exists(processed_indices_file_path):\n",
    "    start_idx = np.load(processed_indices_file_path).item()\n",
    "    print(f\"Continuando o processamento a partir do índice {start_idx}.\")\n",
    "else:\n",
    "    print(\"Iniciando processamento do início.\")\n",
    "\n",
    "# Ajustando textos quando usado amostras\n",
    "if use_sample:\n",
    "    end_idx = min(start_idx + batch_size, len(dados))\n",
    "    dados = dados.iloc[start_idx:end_idx]\n",
    "    print(f\"Usando uma amostra de {len(dados)} registros.\")\n",
    "else:\n",
    "    dados = dados.iloc[start_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807ad6cd-330e-4189-a7df-86816245db22",
   "metadata": {},
   "source": [
    "**Pré-Processamento dos Dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd629ec-6a9e-4cd3-b9d2-649e99089ffe",
   "metadata": {},
   "source": [
    "Utilizamos o tokenizador DistilBERT para processar os textos, combinando título e descrição e aplicando truncamento e padding conforme necessário. Convertendo o DataFrame para um Dataset compatível com a biblioteca Hugging Face, preparamos os dados para o treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32fb2433-c3dc-4ae7-aee0-079469a09a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessamento\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Combinar título e descrição\n",
    "    combined_text = [f\"Título: {title} Descrição: {content}\" for title, content in zip(examples['title'], examples['content'])]\n",
    "    return tokenizer(combined_text, truncation=True, padding='max_length', max_length=512)\n",
    "\n",
    "# Converter DataFrame para Dataset\n",
    "def convert_to_dataset(df):\n",
    "    # Aplicar a função de pré-processamento a todos os textos\n",
    "    encodings = preprocess_function({'title': df['title'].tolist(), 'content': df['content'].tolist()})\n",
    "    encodings['label'] = df['label'].tolist()  # Adicionar rótulos\n",
    "    return Dataset.from_dict(encodings)\n",
    "\n",
    "dataset = convert_to_dataset(dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174f1ecd-365c-4f47-a249-cd7ff0daf97f",
   "metadata": {},
   "source": [
    "**Divisão do dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0e204c-caa0-4076-a7aa-8c249b165d88",
   "metadata": {},
   "source": [
    "O dataset é embaralhado e dividido em dois conjuntos: um para treinamento (80% dos dados) e outro para avaliação (20% dos dados). Isso garante que o modelo seja treinado e testado em dados distintos para uma avaliação justa do seu desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1850c57-3442-4043-9f4c-ea7a727f4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir o dataset em treino e avaliação\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "eval_size = len(dataset) - train_size\n",
    "train_dataset = dataset.select(range(train_size))\n",
    "eval_dataset = dataset.select(range(train_size, train_size + eval_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14937e97-fc6f-4179-89df-d5989ca71d14",
   "metadata": {},
   "source": [
    "**Carregamento do modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f001a7a3-ee6b-4ba3-9acf-6802970537c5",
   "metadata": {},
   "source": [
    "Carregamos o modelo DistilBERT pré-treinado para classificação de sequência, ajustando-o para o número de rótulos no nosso dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b881d35f-c3de-4165-95b6-b8f6673eacd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo inicial carregado.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(set(dados['label'])))\n",
    "print(f\"Modelo inicial carregado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3dc6be-81a3-4927-b6c4-879da8c0a8f0",
   "metadata": {},
   "source": [
    "**Configuração do modelo e argumentos de treinamento**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ae6a8d-f370-46b0-95fd-608fd4e65757",
   "metadata": {},
   "source": [
    "Inicializamos o modelo DistilBERT para classificação de sequência e configuramos os parâmetros de treinamento, incluindo o número de épocas, tamanhos de lote, e estratégias de avaliação e salvamento. Estas configurações ajudam a otimizar o processo de fine-tuning, adaptando o treinamento para o modelo e os dados específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5005342-efc4-4623-a894-32dd810e27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina seu otimizador\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "\n",
    "# Configure os argumentos de treinamento\n",
    "# 1 época 372 segundos\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=diretorio_finetunning_results,\n",
    "    num_train_epochs=3,                        # 1 época para testes rápidos\n",
    "    per_device_train_batch_size=16,            # Reduzir o batch size para liberar mais memória\n",
    "    per_device_eval_batch_size=16,             # Avaliação também com batch pequeno\n",
    "    warmup_steps=0,                            # Remover warmup\n",
    "    weight_decay=0.01,                         # Decaimento de peso\n",
    "    logging_dir=None,                          # Desativar logs\n",
    "    logging_steps=-1,                          # Desativar logs frequentes\n",
    "    eval_strategy='steps',                     # Avaliar a cada X passos\n",
    "    save_strategy='steps',                     # Salvar a cada X passos\n",
    "    save_steps=200000,                         # Salvar menos frequente\n",
    "    eval_steps=200000,                         # Avaliar menos frequente\n",
    "    load_best_model_at_end=True,               # Carregar o melhor modelo no final\n",
    "    save_safetensors=True,                     # Serialização segura\n",
    "    dataloader_num_workers=0,                  # Menos workers para aliviar a CPU\n",
    "    fp16=False,                                # Não usar FP16 em CPU\n",
    "    report_to=None,                            # Desativar relatórios de monitoramento (Ex: TensorBoard)\n",
    "    resume_from_checkpoint=True                # Retomar de um checkpoint anterior\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c622cd77-26aa-41ae-9b83-f566545a1720",
   "metadata": {},
   "source": [
    "**Treinamento, avaliação e salvamento do modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3079db7f-851f-4574-aeba-1c0334800420",
   "metadata": {},
   "source": [
    "Realizamos o treinamento do modelo, monitorando o progresso a cada época com a ajuda de um callback para early stopping. Após cada época, avaliamos o desempenho do modelo, armazenamos as métricas de avaliação, e salvamos o modelo atualizado. Além disso, mantemos o índice de progresso atualizado para continuar o treinamento em execuções futuras, e paar seguir no RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd435d2-7983-458e-bd89-df5f3b96829f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='145' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [145/750 3:09:58 < 13:52:52, 0.01 it/s, Epoch 0.58/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configurar o callback para early stopping\n",
    "early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=2)\n",
    "\n",
    "# Adicionar o callback ao seu treinamento\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    optimizers=(optimizer, None)  # Passar o otimizador AdamW\n",
    ")\n",
    "\n",
    "# Verificar o estado do modelo antes do treinamento\n",
    "\"\"\"\n",
    "Comentado para reduzir o tempo de rodagem. Sendo descomentado algumas vezes para acompanhamento inicial\n",
    "\n",
    "initial_results = {}\n",
    "if os.path.exists(diretorio_finetunning_modelo_final):\n",
    "    initial_results = trainer.evaluate()\n",
    "print(f\"Estado inicial do modelo: {initial_results}\")\n",
    "\"\"\"\n",
    "\n",
    "# Lista para armazenar os valores de loss e epoch\n",
    "eval_losses = []\n",
    "epochs = []\n",
    "\n",
    "# Treinamento com Progress\n",
    "for epoch in range(int(training_args.num_train_epochs)):\n",
    "    trainer.train(resume_from_checkpoint=True)\n",
    "    tqdm.write(f'Epoch {epoch+1}/{int(training_args.num_train_epochs)} complete.')\n",
    "    \n",
    "    # Avaliar o modelo\n",
    "    results = trainer.evaluate()\n",
    "\n",
    "    # Armazenar eval_loss e epoch\n",
    "    eval_losses.append(results['eval_loss'])\n",
    "    epochs.append(epoch + 1)\n",
    "    \n",
    "    # Imprimir resultados da avaliação após cada época\n",
    "    print(f'Results após Epoch {epoch+1}: {results}')\n",
    "\n",
    "    # Salvar o modelo\n",
    "    trainer.save_model(diretorio_finetunning_modelo_final)\n",
    "    print(f\"Modelo salvo em '{diretorio_finetunning_modelo_final}'.\")\n",
    "\n",
    "    # Atualizar índice processado\n",
    "    np.save(processed_indices_file_path, end_idx)\n",
    "    print(f\"Índice processado atualizado: {end_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c3b5b5-8f7b-449b-bf3d-003415218c69",
   "metadata": {},
   "source": [
    "**Gráfico**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea52db48-0e6e-4336-bf64-bbe941893fec",
   "metadata": {},
   "source": [
    "Geramos um gráfico para visualizar a variação do loss durante o treinamento do modelo. O gráfico mostra o loss em função das épocas, facilitando a análise do desempenho do modelo ao longo do tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915f5194-e164-4928-b2f0-3be885e8fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar o gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, eval_losses, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Avaliação de Loss por Época')\n",
    "plt.grid(True)\n",
    "plt.xticks(range(1, int(training_args.num_train_epochs) + 1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
