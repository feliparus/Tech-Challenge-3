{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae3380c-2034-4aac-a35d-dc90dfe1b9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: deep-translator in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python312\\site-packages (1.11.4)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python312\\site-packages (from deep-translator) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python312\\site-packages (from deep-translator) (2.32.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python312\\site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310e6012-b6af-489a-88c5-c8fc0b555a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "from include.utils import *\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b162336-c8ff-4029-97f5-75877b8a9495",
   "metadata": {},
   "source": [
    "**Objetivo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caab9d0-31eb-42d9-ba02-b8cf5945426c",
   "metadata": {},
   "source": [
    "O objetivo deste script é demonstrar como usar um modelo BERT pré-treinado para responder a perguntas com base em um conjunto de dados. Este exemplo ilustra o processo de geração de respostas sem técnicas avançadas como fine-tuning ou Retrieval-Augmented Generation (RAG). Utilizamos um modelo de perguntas e respostas para mostrar a aplicação básica dessa técnica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c81a1-5ab9-4ffa-84f2-782b9d92e867",
   "metadata": {},
   "source": [
    "**Preparação dos dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9513118c-d8b0-4185-9c1b-be6729a7ffde",
   "metadata": {},
   "source": [
    "Obtemos o arquivo parquet gerado e aplicamos uma amostragem opcional para limitar o tamanho do dataset, facilitando o teste inicial do fluxo de trabalho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6acedf15-7ffa-4a0a-906a-d9765543b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal_width = os.get_terminal_size().columns\n",
    "\n",
    "diretorio_arquivos = '../arquivos'\n",
    "parquet_file_path = os.path.join(diretorio_arquivos, 'trn.parquet')\n",
    "\n",
    "# Carregar DataFrame do Parquet\n",
    "dados = load_dataframe(parquet_file_path)\n",
    "\n",
    "# Configurações de amostragem\n",
    "batch_size = 50\n",
    "use_sample = True\n",
    "\n",
    "# Amostrar dados se necessário\n",
    "if use_sample:\n",
    "    dados = dados.sample(n=batch_size, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed7793b-5281-4ecd-a5d2-f01b1ebc41c4",
   "metadata": {},
   "source": [
    "**Carregamento do Modelo e Tokenizador**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09428362-8b5e-402e-91ff-5232210d3fb5",
   "metadata": {},
   "source": [
    "Carregando o modelo BERT pré-treinado e o tokenizador, configurando dois modelos: um para codificação de texto e outro para tarefas de perguntas e respostas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f88ee635-16b5-43f9-98f0-f798b0fd54ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luiz.santos\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Carregar o modelo pré-treinado e o tokenizador\n",
    "model_name = 'bert-large-uncased-whole-word-masking-finetuned-squad'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8ff0ba-a825-40b7-9ae1-99a8e1fa4a0c",
   "metadata": {},
   "source": [
    "**Definição da Função de Perguntas e Respostas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91c5523-b75c-4b47-913f-cfeecdea38f6",
   "metadata": {},
   "source": [
    "Define uma função para gerar respostas com base em uma pergunta e um contexto fornecido. Utiliza o modelo BERT para identificar a resposta mais provável no contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45b79865-f77e-4c7e-87e5-9cc995cf3c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Yellow Box Women's Yulisa Flip Flop Sandal\n",
      "Context: Nenhum contexto fornecido.\n",
      "Resposta: Nenhuma resposta encontrada.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Title: Nine West Women's Eastnor Sandal\n",
      "Context: Nenhum contexto fornecido.\n",
      "Resposta: Nenhuma resposta encontrada.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Title: Roma Costume Women's 1 Piece Santa's Envy-Red White\n",
      "Context: Nenhum contexto fornecido.\n",
      "Resposta: Nenhuma resposta encontrada.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'resposta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m resposta_en \u001b[38;5;241m=\u001b[39m obter_resposta(pergunta, contexto)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Traduzir resposta para português\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m resposta_pt \u001b[38;5;241m=\u001b[39m traduzir_texto(resposta)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Imprimir resultado formatado\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitulo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'resposta' is not defined"
     ]
    }
   ],
   "source": [
    "# Inicializar tradutor\n",
    "translator = GoogleTranslator(source='en', target='pt')\n",
    "\n",
    "def obter_resposta(pergunta, contexto):\n",
    "    # Preparar entrada para o modelo\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        pergunta,\n",
    "        contexto,\n",
    "        return_tensors='pt',\n",
    "        max_length=512,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    # Obter saída do modelo\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Encontrar índice inicial e final da resposta\n",
    "    start_index = torch.argmax(outputs.start_logits)\n",
    "    end_index = torch.argmax(outputs.end_logits) + 1\n",
    "\n",
    "    # Obter tokens de resposta\n",
    "    resposta_tokens = input_ids[0][start_index:end_index]\n",
    "    resposta = tokenizer.decode(resposta_tokens, skip_special_tokens=True)\n",
    "\n",
    "    return resposta\n",
    "\n",
    "def traduzir_texto(texto):\n",
    "    # Traduzir texto para o português\n",
    "    traducao = translator.translate(texto)\n",
    "    return traducao\n",
    "\n",
    "pergunta = \"Qual é a característica principal deste produto ?\"\n",
    "\n",
    "# Criar contextos a partir das amostras\n",
    "contextos = [f\"Title: {row['title']} Content: {row['content']}\" for _, row in dados.iterrows()]\n",
    "\n",
    "# Testar o modelo com as amostras\n",
    "for _, row in dados.iterrows():\n",
    "    titulo = row['title']\n",
    "    contexto = row['content']\n",
    "\n",
    "    if not contexto.strip():  # Verifica se o contexto está vazio\n",
    "        print(f\"Title: {titulo}\")\n",
    "        print(\"Context: Nenhum contexto fornecido.\")\n",
    "        print(\"Resposta: Nenhuma resposta encontrada.\\n\")\n",
    "        print('-' * terminal_width)\n",
    "        continue\n",
    "\n",
    "    # Traduzir contexto para português\n",
    "    contexto_pt = traduzir_texto(contexto)\n",
    "\n",
    "    # Obter resposta\n",
    "    resposta_en = obter_resposta(pergunta, contexto)\n",
    "\n",
    "    # Traduzir resposta para português\n",
    "    resposta_pt = traduzir_texto(resposta_en)\n",
    "\n",
    "    # Imprimir resultado formatado\n",
    "    print(f\"Title: {titulo}\")\n",
    "    print(f\"Contexto em inglês: {contexto}\")\n",
    "    print(f\"Contexto traduzido: {contexto_pt}\")\n",
    "    print(f\"Resposta em inglês: {resposta_en}\")\n",
    "    print(f\"Resposta traduzida: {resposta_pt}\\n\")\n",
    "    print('-' * terminal_width)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
