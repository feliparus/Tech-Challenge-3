{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be29ad36-4d6d-45ef-8927-a6a6afb32394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as funções do arquivo baixar_documento.py\n",
    "from include.baixar_documento import *\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32780db-1b50-4a52-b84b-1003e128f13a",
   "metadata": {},
   "source": [
    "**Declaração de variáveis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56e2e18-6ed9-427e-b456-37c6038bac34",
   "metadata": {},
   "source": [
    "Nesta seção, preparamos as variáveis necessárias para sequência do Tech Challenge.\n",
    "\n",
    "Para geração do json em um dataset, decidimos usar parquet. O formato Parquet é eficiente em termos de armazenamento e desempenho, utilizando compactação e codificação colunar para reduzir o tamanho dos arquivos e melhorar a leitura e escrita. Ele suporta tipos de dados complexos e é amplamente compatível com ferramentas de big data, tornando-o ideal para grandes volumes de dados e análises rápidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73610b88-48da-4222-9692-7d37986804e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém a largura do terminal - uso mais embaixo nos prints\n",
    "terminal_width = os.get_terminal_size().columns\n",
    "\n",
    "url = 'https://drive.google.com/uc?id=12zH4mL2RX8iSvH0VCNnd3QxO4DzuHWnK'\n",
    "diretorio_arquivos = '../arquivos'\n",
    "json_file_para_extrair = 'trn.json'\n",
    "parquet_file = \"trn.parquet\"\n",
    "gz_file_para_extrair = 'LF-Amazon-1.3M/trn.json.gz'\n",
    "\n",
    "json_file_path = os.path.join(diretorio_arquivos, json_file_para_extrair)\n",
    "parquet_file_path = os.path.join(diretorio_arquivos, parquet_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e1699b-121d-4347-ba33-9f2a52ebd90d",
   "metadata": {},
   "source": [
    "**Tratamento arquivo alvo json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f251a848-570b-43b2-90b6-c0e9c415ea73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de linhas no json: 2248619\n"
     ]
    }
   ],
   "source": [
    "# Verificar se o arquivo JSON já existe\n",
    "if not os.path.exists(json_file_path):\n",
    "    # Executando o download e extração\n",
    "    zip_data = baixar_arquivo_zip(url)\n",
    "    extracted_file_path = extrair_arquivo_gz_do_zip(zip_data, gz_file_para_extrair, diretorio_arquivos, json_file_para_extrair)\n",
    "else:\n",
    "    extracted_file_path = json_file_path\n",
    "\n",
    "total_linhas_json = contar_linhas_json(extracted_file_path)\n",
    "print(f\"Número total de linhas no json: {total_linhas_json}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b738d89-d7c0-4577-b6af-91b77b7bb4d1",
   "metadata": {},
   "source": [
    "**Geração dataset para finetunning e rag**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10d247db-a654-4090-995e-08e9f41a32b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Lista de todas colunas:\n",
      "\n",
      " ['uid', 'title', 'content', 'target_ind', 'target_rel']\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Amostra dos dados:\n",
      "\n",
      "           uid                                              title  \\\n",
      "0  0000031909                        Girls Ballet Tutu Neon Pink   \n",
      "1  0000032034                           Adult Ballet Tutu Yellow   \n",
      "2  0000913154  The Way Things Work: An Illustrated Encycloped...   \n",
      "3  0001360000                                      Mog's Kittens   \n",
      "4  0001381245                              Misty of Chincoteague   \n",
      "\n",
      "                                             content  \\\n",
      "0  High quality 3 layer ballet tutu. 12 inches in...   \n",
      "1                                                      \n",
      "2                                                      \n",
      "3  Judith Kerr&#8217;s best&#8211;selling adventu...   \n",
      "4                                                      \n",
      "\n",
      "                                          target_ind  \\\n",
      "0  [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 2...   \n",
      "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 16, 33, 36, 37,...   \n",
      "2                [116, 117, 118, 119, 120, 121, 122]   \n",
      "3                          [146, 147, 148, 149, 495]   \n",
      "4                                              [151]   \n",
      "\n",
      "                                          target_rel  \n",
      "0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
      "1  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
      "2                [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  \n",
      "3                          [1.0, 1.0, 1.0, 1.0, 1.0]  \n",
      "4                                              [1.0]  \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Quantidade de linhas: 2248619. Quantidade de colunas: 5\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Tipos de dados das colunas:\n",
      "\n",
      " uid           object\n",
      "title         object\n",
      "content       object\n",
      "target_ind    object\n",
      "target_rel    object\n",
      "dtype: object\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Quantidade de valores ausentes por coluna:\n",
      "\n",
      " uid           0\n",
      "title         0\n",
      "content       0\n",
      "target_ind    0\n",
      "target_rel    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verifica se o arquivo Parquet já existe\n",
    "if not os.path.exists(parquet_file_path):\n",
    "    # Lendo o arquivo JSON extraído usando Pandas\n",
    "    dados = read_large_json_with_pandas(extracted_file_path, num_lines=None)  # Lê todo o arquivo JSON\n",
    "    save_dataframe(dados, parquet_file_path)  # Salva o DataFrame em um arquivo Parquet\n",
    "else:\n",
    "    # Carregar o DataFrame do arquivo Parquet existente\n",
    "    dados = load_dataframe(parquet_file_path)\n",
    "\n",
    "# Imprimindo detalhes necessários\n",
    "print('-' * terminal_width)\n",
    "print(\"\\nLista de todas colunas:\\n\\n\", list(dados))\n",
    "print('-' * terminal_width)\n",
    "print(\"\\nAmostra dos dados:\\n\\n\", dados.head())\n",
    "print('-' * terminal_width)\n",
    "print(f\"\\nQuantidade de linhas: {dados.shape[0]}. Quantidade de colunas: {dados.shape[1]}\")\n",
    "print('-' * terminal_width)\n",
    "print(\"\\nTipos de dados das colunas:\\n\\n\", dados.dtypes)\n",
    "print('-' * terminal_width)\n",
    "print(\"\\nQuantidade de valores ausentes por coluna:\\n\\n\", dados.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21741cff-b653-493e-ae6b-183a28facd66",
   "metadata": {},
   "source": [
    "**Teste Inicial com o Modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4d7edd-cf76-4871-9792-c958cce694e5",
   "metadata": {},
   "source": [
    "Objetivo: Verificar se o modelo pré-treinado responde com sentido a uma pergunta baseada nos dados.\n",
    "\n",
    "Passos:\n",
    "\n",
    "Carregue o Dataset: Carregue o dataset dados e selecione apenas as colunas uid, title e content.\n",
    "Escolha uma Pergunta: Faça uma pergunta que deveria ser respondida com base nas informações do dataset.\n",
    "Teste com o Modelo: Use o modelo pré-treinado para responder a essa pergunta e verifique a relevância da resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b90d6af-3552-4934-8185-1811ce421f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta do modelo pré-treinado: Resposta gerada pelo modelo pré-treinado\n"
     ]
    }
   ],
   "source": [
    "dados = dados[['uid', 'title', 'content']]\n",
    "\n",
    "# Exemplo de pergunta\n",
    "pergunta = \"Qual é a característica principal do produto XYZ?\"\n",
    "\n",
    "# Função para obter resposta do modelo pré-treinado (substitua com sua chamada de API ou modelo)\n",
    "def obter_resposta(pergunta):\n",
    "    # Exemplo fictício\n",
    "    return \"Resposta gerada pelo modelo pré-treinado\"\n",
    "\n",
    "# Testar o modelo\n",
    "resposta = obter_resposta(pergunta)\n",
    "print(\"Resposta do modelo pré-treinado:\", resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c396993-845a-4dd1-923d-7f0d9f33b648",
   "metadata": {},
   "source": [
    "**Aplicar RAG para Recuperação e Geração**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c903f951-7c51-418f-b704-160ef5eee372",
   "metadata": {},
   "source": [
    "Objetivo: Melhorar a precisão das respostas usando recuperação de informações relevantes dos documentos e geração de texto.\n",
    "\n",
    "Passos:\n",
    "\n",
    "Preparar o Índice de Recuperação:\n",
    "\n",
    "Tokenização e Indexação: Use ferramentas como FAISS para criar um índice com os documentos no dataset.\n",
    "Criação de Embeddings: Gere embeddings dos documentos e adicione ao índice.\n",
    "Recuperação de Documentos:\n",
    "\n",
    "Consulta: Quando uma pergunta é feita, recupere documentos relevantes usando o índice.\n",
    "Geração de Respostas:\n",
    "\n",
    "Contexto: Passe os documentos recuperados como contexto para o modelo de linguagem gerar a resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f946de-997c-4860-bece-1215e2a079c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/nightly/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.4.0+cpu)\n",
      "Requirement already satisfied: torchvision in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.19.0+cpu)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.4.0+cpu)\n",
      "Requirement already satisfied: filelock in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (70.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9cbe909-d6bc-4f5f-a696-334c024e5c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.4.0-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.19.0-1-cp311-cp311-win_amd64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.4.0-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.12.2)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.1.4)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting numpy<2 (from torchvision)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.0/61.0 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading pillow-10.4.0-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.7.24-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.5/41.5 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.4-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.4.0-cp311-cp311-win_amd64.whl (197.9 MB)\n",
      "   ---------------------------------------- 0.0/197.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/197.9 MB 4.3 MB/s eta 0:00:47\n",
      "   ---------------------------------------- 0.3/197.9 MB 4.2 MB/s eta 0:00:48\n",
      "   ---------------------------------------- 0.5/197.9 MB 4.3 MB/s eta 0:00:47\n",
      "   ---------------------------------------- 0.7/197.9 MB 4.2 MB/s eta 0:00:48\n",
      "   ---------------------------------------- 1.0/197.9 MB 4.6 MB/s eta 0:00:43\n",
      "   ---------------------------------------- 1.2/197.9 MB 4.5 MB/s eta 0:00:44\n",
      "   ---------------------------------------- 1.5/197.9 MB 4.7 MB/s eta 0:00:42\n",
      "   ---------------------------------------- 1.8/197.9 MB 4.9 MB/s eta 0:00:41\n",
      "   ---------------------------------------- 2.1/197.9 MB 5.0 MB/s eta 0:00:40\n",
      "   ---------------------------------------- 2.2/197.9 MB 5.3 MB/s eta 0:00:38\n",
      "   ---------------------------------------- 2.5/197.9 MB 4.8 MB/s eta 0:00:42\n",
      "    --------------------------------------- 2.8/197.9 MB 4.9 MB/s eta 0:00:40\n",
      "    --------------------------------------- 2.8/197.9 MB 5.0 MB/s eta 0:00:39\n",
      "    --------------------------------------- 2.8/197.9 MB 5.0 MB/s eta 0:00:39\n",
      "    --------------------------------------- 3.1/197.9 MB 4.4 MB/s eta 0:00:45\n",
      "    --------------------------------------- 3.1/197.9 MB 4.3 MB/s eta 0:00:46\n",
      "    --------------------------------------- 3.1/197.9 MB 4.3 MB/s eta 0:00:46\n",
      "    --------------------------------------- 3.3/197.9 MB 3.9 MB/s eta 0:00:50\n",
      "    --------------------------------------- 3.4/197.9 MB 3.9 MB/s eta 0:00:50\n",
      "    --------------------------------------- 3.6/197.9 MB 3.9 MB/s eta 0:00:50\n",
      "    --------------------------------------- 3.8/197.9 MB 3.9 MB/s eta 0:00:50\n",
      "    --------------------------------------- 4.1/197.9 MB 4.1 MB/s eta 0:00:48\n",
      "    --------------------------------------- 4.2/197.9 MB 4.1 MB/s eta 0:00:48\n",
      "    --------------------------------------- 4.5/197.9 MB 4.1 MB/s eta 0:00:47\n",
      "    --------------------------------------- 4.6/197.9 MB 4.1 MB/s eta 0:00:48\n",
      "    --------------------------------------- 4.9/197.9 MB 4.1 MB/s eta 0:00:48\n",
      "    --------------------------------------- 4.9/197.9 MB 4.1 MB/s eta 0:00:48\n",
      "    --------------------------------------- 4.9/197.9 MB 4.1 MB/s eta 0:00:48\n",
      "   - -------------------------------------- 5.3/197.9 MB 3.9 MB/s eta 0:00:49\n",
      "   - -------------------------------------- 5.4/197.9 MB 3.9 MB/s eta 0:00:50\n",
      "   - -------------------------------------- 5.7/197.9 MB 4.0 MB/s eta 0:00:49\n",
      "   - -------------------------------------- 5.8/197.9 MB 4.0 MB/s eta 0:00:49\n",
      "   - -------------------------------------- 6.3/197.9 MB 4.1 MB/s eta 0:00:47\n",
      "   - -------------------------------------- 6.6/197.9 MB 4.2 MB/s eta 0:00:46\n",
      "   - -------------------------------------- 6.6/197.9 MB 4.1 MB/s eta 0:00:47\n",
      "   - -------------------------------------- 6.6/197.9 MB 4.1 MB/s eta 0:00:47\n",
      "   - -------------------------------------- 6.9/197.9 MB 4.0 MB/s eta 0:00:48\n",
      "   - -------------------------------------- 7.1/197.9 MB 4.1 MB/s eta 0:00:47\n",
      "   - -------------------------------------- 7.4/197.9 MB 4.1 MB/s eta 0:00:47\n",
      "   - -------------------------------------- 7.5/197.9 MB 4.1 MB/s eta 0:00:47\n",
      "   - -------------------------------------- 8.0/197.9 MB 4.2 MB/s eta 0:00:45\n",
      "   - -------------------------------------- 8.7/197.9 MB 4.5 MB/s eta 0:00:43\n",
      "   - -------------------------------------- 9.2/197.9 MB 4.6 MB/s eta 0:00:41\n",
      "   - -------------------------------------- 9.3/197.9 MB 4.6 MB/s eta 0:00:42\n",
      "   -- ------------------------------------- 10.0/197.9 MB 4.8 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 11.0/197.9 MB 5.3 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 11.6/197.9 MB 5.6 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 11.6/197.9 MB 5.6 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 11.6/197.9 MB 5.6 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 12.3/197.9 MB 5.4 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 13.3/197.9 MB 6.2 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 13.5/197.9 MB 6.5 MB/s eta 0:00:29\n",
      "   -- ------------------------------------- 14.3/197.9 MB 7.1 MB/s eta 0:00:26\n",
      "   --- ------------------------------------ 15.0/197.9 MB 7.9 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 15.3/197.9 MB 8.4 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 15.9/197.9 MB 9.0 MB/s eta 0:00:21\n",
      "   --- ------------------------------------ 16.8/197.9 MB 9.8 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 17.8/197.9 MB 12.1 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 19.2/197.9 MB 13.1 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 20.1/197.9 MB 14.2 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 21.0/197.9 MB 14.6 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 22.2/197.9 MB 16.8 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 23.7/197.9 MB 19.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 25.1/197.9 MB 21.8 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 26.4/197.9 MB 25.2 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 27.6/197.9 MB 25.2 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 29.4/197.9 MB 27.3 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 31.6/197.9 MB 34.4 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 32.8/197.9 MB 32.7 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 33.9/197.9 MB 29.8 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 35.8/197.9 MB 34.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 37.9/197.9 MB 34.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 38.9/197.9 MB 34.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 40.4/197.9 MB 34.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 42.8/197.9 MB 34.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 45.4/197.9 MB 40.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 47.1/197.9 MB 43.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 48.3/197.9 MB 38.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 48.3/197.9 MB 38.5 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 51.0/197.9 MB 36.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 53.6/197.9 MB 38.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 54.7/197.9 MB 34.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 55.8/197.9 MB 31.2 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 57.8/197.9 MB 32.7 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 60.3/197.9 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 61.2/197.9 MB 36.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 63.1/197.9 MB 32.8 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 65.1/197.9 MB 38.6 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 67.4/197.9 MB 38.5 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 69.6/197.9 MB 40.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 71.4/197.9 MB 43.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 73.9/197.9 MB 46.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 76.0/197.9 MB 46.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 78.1/197.9 MB 43.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 80.4/197.9 MB 46.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 82.7/197.9 MB 46.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 84.9/197.9 MB 43.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 87.3/197.9 MB 46.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 89.3/197.9 MB 50.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 91.9/197.9 MB 46.9 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 94.0/197.9 MB 50.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 96.6/197.9 MB 46.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 98.7/197.9 MB 46.7 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 101.1/197.9 MB 46.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 103.3/197.9 MB 46.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 105.5/197.9 MB 46.7 MB/s eta 0:00:02\n",
      "   --------------------- ----------------- 107.7/197.9 MB 46.9 MB/s eta 0:00:02\n",
      "   --------------------- ----------------- 110.0/197.9 MB 46.9 MB/s eta 0:00:02\n",
      "   ---------------------- ---------------- 112.4/197.9 MB 46.7 MB/s eta 0:00:02\n",
      "   ---------------------- ---------------- 114.6/197.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 116.9/197.9 MB 46.7 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 119.3/197.9 MB 46.7 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 121.5/197.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 124.1/197.9 MB 43.7 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 126.4/197.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 128.9/197.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 131.5/197.9 MB 54.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 133.8/197.9 MB 54.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 136.4/197.9 MB 50.1 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 138.4/197.9 MB 50.4 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 140.8/197.9 MB 46.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 143.5/197.9 MB 50.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 145.6/197.9 MB 46.7 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 148.0/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 150.6/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 153.4/197.9 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 155.5/197.9 MB 50.1 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 158.0/197.9 MB 54.7 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 160.6/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 162.5/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 165.3/197.9 MB 59.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 168.1/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 170.6/197.9 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 173.0/197.9 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 175.6/197.9 MB 54.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 177.6/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 179.8/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 182.3/197.9 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 184.5/197.9 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 186.5/197.9 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 188.8/197.9 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 191.3/197.9 MB 46.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  193.3/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  195.9/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.9/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.9/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.9/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.9/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.9/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.9/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.9/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.9/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.9/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.9/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.9/197.9 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 197.9/197.9 MB 14.5 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.19.0-1-cp311-cp311-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 41.2 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.4.0-cp311-cp311-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 1.8/2.4 MB 56.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 38.2 MB/s eta 0:00:00\n",
      "Using cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "Downloading huggingface_hub-0.24.6-py3-none-any.whl (417 kB)\n",
      "   ---------------------------------------- 0.0/417.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 417.5/417.5 kB 25.5 MB/s eta 0:00:00\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.1/15.8 MB 34.0 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 2.0/15.8 MB 25.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 3.3/15.8 MB 26.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 5.1/15.8 MB 29.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.5/15.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 9.1/15.8 MB 34.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.3/15.8 MB 33.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.3/15.8 MB 33.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.3/15.8 MB 33.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.3/15.8 MB 33.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.3/15.8 MB 33.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.3/15.8 MB 33.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.0/15.8 MB 19.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 18.2 MB/s eta 0:00:00\n",
      "Downloading pillow-10.4.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 2.1/2.6 MB 68.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 40.4 MB/s eta 0:00:00\n",
      "Downloading regex-2024.7.24-cp311-cp311-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 269.7/269.7 kB ? eta 0:00:00\n",
      "Downloading safetensors-0.4.4-cp311-none-win_amd64.whl (285 kB)\n",
      "   ---------------------------------------- 0.0/286.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 286.0/286.0 kB 17.2 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 51.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 35.6 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.4/78.4 kB ? eta 0:00:00\n",
      "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, tqdm, sympy, safetensors, regex, pillow, numpy, networkx, fsspec, filelock, torch, huggingface-hub, torchvision, torchaudio, tokenizers, transformers\n",
      "Successfully installed filelock-3.15.4 fsspec-2024.6.1 huggingface-hub-0.24.6 mpmath-1.3.0 networkx-3.3 numpy-1.26.4 pillow-10.4.0 regex-2024.7.24 safetensors-0.4.4 sympy-1.13.2 tokenizers-0.19.1 torch-2.4.0 torchaudio-2.4.0 torchvision-0.19.0 tqdm-4.66.5 transformers-4.44.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'C:\\Users\\luiz.santos\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script isympy.exe is installed in 'C:\\Users\\luiz.santos\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\luiz.santos\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'C:\\Users\\luiz.santos\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\luiz.santos\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\luiz.santos\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\luiz.santos\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2024.7.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install torch torchvision torchaudio transformers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install --upgrade transformers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(transformers\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio transformers\n",
    "!pip install --upgrade transformers\n",
    "\n",
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aacd4fa-e4be-4e46-9316-217cc67dd07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb25960e-d882-4217-aa34-0fb2bf994574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9c3c590-9acc-48da-ae6b-e083321cc825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.4.0+cpu)\n",
      "Requirement already satisfied: filelock in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (70.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.44.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\luiz.santos\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "   ---------------------------------------- 0.0/9.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 3.1/9.5 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.1/9.5 MB 21.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.5/9.5 MB 19.7 MB/s eta 0:00:00\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.44.0\n",
      "    Uninstalling transformers-4.44.0:\n",
      "      Successfully uninstalled transformers-4.44.0\n",
      "Successfully installed transformers-4.44.2\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 126] Não foi possível encontrar o módulo especificado. Error loading \"C:\\Users\\luiz.santos\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install --upgrade transformers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfaiss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IndexFlatL2\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModel\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Tokenizador e modelo pré-treinado\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     logging,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     52\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\__init__.py:34\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m     28\u001b[0m     add_end_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     33\u001b[0m )\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     35\u001b[0m     ContextManagers,\n\u001b[0;32m     36\u001b[0m     ExplicitEnum,\n\u001b[0;32m     37\u001b[0m     ModelOutput,\n\u001b[0;32m     38\u001b[0m     PaddingStrategy,\n\u001b[0;32m     39\u001b[0m     TensorType,\n\u001b[0;32m     40\u001b[0m     add_model_info_to_auto_map,\n\u001b[0;32m     41\u001b[0m     add_model_info_to_custom_pipelines,\n\u001b[0;32m     42\u001b[0m     cached_property,\n\u001b[0;32m     43\u001b[0m     can_return_loss,\n\u001b[0;32m     44\u001b[0m     expand_dims,\n\u001b[0;32m     45\u001b[0m     filter_out_non_signature_kwargs,\n\u001b[0;32m     46\u001b[0m     find_labels,\n\u001b[0;32m     47\u001b[0m     flatten_dict,\n\u001b[0;32m     48\u001b[0m     infer_framework,\n\u001b[0;32m     49\u001b[0m     is_jax_tensor,\n\u001b[0;32m     50\u001b[0m     is_numpy_array,\n\u001b[0;32m     51\u001b[0m     is_tensor,\n\u001b[0;32m     52\u001b[0m     is_tf_symbolic_tensor,\n\u001b[0;32m     53\u001b[0m     is_tf_tensor,\n\u001b[0;32m     54\u001b[0m     is_torch_device,\n\u001b[0;32m     55\u001b[0m     is_torch_dtype,\n\u001b[0;32m     56\u001b[0m     is_torch_tensor,\n\u001b[0;32m     57\u001b[0m     reshape,\n\u001b[0;32m     58\u001b[0m     squeeze,\n\u001b[0;32m     59\u001b[0m     strtobool,\n\u001b[0;32m     60\u001b[0m     tensor_size,\n\u001b[0;32m     61\u001b[0m     to_numpy,\n\u001b[0;32m     62\u001b[0m     to_py_obj,\n\u001b[0;32m     63\u001b[0m     torch_float,\n\u001b[0;32m     64\u001b[0m     torch_int,\n\u001b[0;32m     65\u001b[0m     transpose,\n\u001b[0;32m     66\u001b[0m     working_or_temp_dir,\n\u001b[0;32m     67\u001b[0m )\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     69\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[0;32m     70\u001b[0m     HF_MODULES_CACHE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     96\u001b[0m     try_to_load_from_cache,\n\u001b[0;32m     97\u001b[0m )\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     99\u001b[0m     ACCELERATE_MIN_VERSION,\n\u001b[0;32m    100\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     torch_only_method,\n\u001b[0;32m    220\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\generic.py:462\u001b[0m\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 462\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_torch_pytree\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_model_output_flatten\u001b[39m(output: ModelOutput) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[Any], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_pytree.Context\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output\u001b[38;5;241m.\u001b[39mvalues()), \u001b[38;5;28mlist\u001b[39m(output\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py:148\u001b[0m\n\u001b[0;32m    146\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    147\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 148\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    150\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] Não foi possível encontrar o módulo especificado. Error loading \"C:\\Users\\luiz.santos\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "from faiss import IndexFlatL2\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "\n",
    "# Tokenizador e modelo pré-treinado\n",
    "tokenizer = AutoTokenizer.from_pretrained('modelo-pretreinado')\n",
    "model = AutoModel.from_pretrained('modelo-pretreinado')\n",
    "\n",
    "# Função para criar embeddings\n",
    "def criar_embeddings(textos):\n",
    "    inputs = tokenizer(textos, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings.numpy()\n",
    "\n",
    "# Criar índice de recuperação\n",
    "documentos = dados['content'].tolist()\n",
    "embeddings = criar_embeddings(documentos)\n",
    "index = IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "# Função de recuperação\n",
    "def recuperar_documentos(pergunta, k=5):\n",
    "    pergunta_embedding = criar_embeddings([pergunta])\n",
    "    distâncias, indices = index.search(pergunta_embedding, k)\n",
    "    return [documentos[i] for i in indices[0]]\n",
    "\n",
    "# Função para gerar resposta usando documentos recuperados\n",
    "def gerar_resposta(pergunta):\n",
    "    documentos_relevantes = recuperar_documentos(pergunta)\n",
    "    contexto = \" \".join(documentos_relevantes)\n",
    "    resposta = obter_resposta(f\"{contexto} Pergunta: {pergunta}\")\n",
    "    return resposta\n",
    "\n",
    "# Testar o modelo com RAG\n",
    "resposta_rag = gerar_resposta(pergunta)\n",
    "print(\"Resposta do modelo com RAG:\", resposta_rag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410b73c7-635d-4245-a64a-cdcda21dc4cd",
   "metadata": {},
   "source": [
    "**Aplicar Fine-Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e55740-00da-48fb-bcac-a967c5f3a68c",
   "metadata": {},
   "source": [
    "Objetivo: Ajustar o modelo para responder de maneira mais precisa e consistente com o estilo dos documentos.\n",
    "\n",
    "Passos:\n",
    "\n",
    "Preparar Dados para Fine-Tuning:\n",
    "\n",
    "Formatação: Crie um dataset de treinamento a partir das perguntas e respostas baseadas no conteúdo dos documentos.\n",
    "Fine-Tuning:\n",
    "\n",
    "Treinamento: Ajuste o modelo pré-treinado usando o dataset preparado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eee468b-b9cd-4d52-aef3-a3429d58874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "\n",
    "# Preparar o modelo para fine-tuning\n",
    "modelo_finetuned = AutoModelForSequenceClassification.from_pretrained('modelo-pretreinado')\n",
    "\n",
    "# Preparar argumentos de treinamento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "# Treinar o modelo\n",
    "trainer = Trainer(\n",
    "    model=modelo_finetuned,\n",
    "    args=training_args,\n",
    "    train_dataset=seu_dataset_de_treinamento,  # Substitua pelo seu dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbacc5f3-5da7-420b-bc14-efb543d856d0",
   "metadata": {},
   "source": [
    "**Resumo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbde95c-8877-400c-9b99-9d4fc8d8bb0a",
   "metadata": {},
   "source": [
    "**Teste Inicial**: Verifique a resposta do modelo pré-treinado para uma pergunta.\n",
    "    \n",
    "**RAG**: Use recuperação de documentos e geração de texto para melhorar a precisão das respostas.\n",
    "\n",
    "**Fine-Tuning**: Ajuste o modelo com base no conteúdo específico para adaptar o estilo e a precisão das respostas.\n",
    "    \n",
    "Essas etapas permitem que você teste e ajuste o modelo para obter respostas mais precisas e relevantes com base no seu dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
